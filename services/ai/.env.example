# Server configuration
HOST=0.0.0.0
PORT=8081
LOG_LEVEL=INFO
DEBUG=false
ENVIRONMENT=production

# API configuration
API_TITLE=AgentChat API
API_DESCRIPTION=API for interacting with the AI agent
API_VERSION=0.2.0

# Frontend URL for CORS
FRONTEND_URL=https://fromfirstprinciple.com/agent/,http://localhost:3000

# Model configuration
GEMINI_MODEL=gemini-3-flash
GEMINI_MODEL_PRO=gemini-3-pro

# Model provider: 'gemini' or 'ollama'
MODEL_PROVIDER=gemini

# Ollama configuration (used when MODEL_PROVIDER=ollama)
OLLAMA_API_BASE=http://localhost:11434
OLLAMA_MODEL=mistral-small3.1
OLLAMA_MODEL_PRO=llama3.2

# Authentication
AUTH_SECRET=testest

# Data configuration
# Determines how the application accesses reference documents.
# Use 'GCS' for signed URLs to Google Cloud Storage (production recommended).
# Use 'LOCAL' to serve files from the local 'testdata' directory via an API endpoint (for development).
FILE_ACCESS_METHOD=local
AGREEMENT_MAPPING_CSV=Agreement_Mapping_with_Filenames.csv
# Specifies the directory containing local test data. Used when FILE_ACCESS_METHOD is 'LOCAL'.
TESTDATA_DIR=testdata

# Development settings
RESTART_SCRIPT_PATH=./scripts/restart-server.sh

# --- Legacy configuration (for reference) ---
# The following variables may still be used by other parts of the system

# Model access: Google AI Studio API or Vertex AI API(through GCP project)
GOOGLE_GENAI_USE_VERTEXAI=FALSE

# For Google AI Studio API (GOOGLE_GENAI_USE_VERTEXAI=FALSE)
GOOGLE_API_KEY=${GEMINI_API_KEY}

